{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Read in Kaggle df</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path_kaggle = r'C:\\Users\\Desktop\\MSBA Coursework\\Tools for Analytics\\datafile'\\amazon_com_extras.csv'\n",
    "\n",
    "with open(path_kaggle):\n",
    "    #Added fields since line 808 in csv has more than 6 cols and needs to be told to ignore extra data.\n",
    "    \n",
    "    fields=['ASIN','GROUP','FORMAT','TITLE','AUTHOR','PUBLISHER']\n",
    "    df_kaggle = pd.read_csv(path_kaggle, encoding='latin1', dtype=str,usecols=fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Read in amazon_com_extras. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "import json\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "\n",
    "my_csvfile=r'C:\\Users\\Desktop\\MSBA Coursework\\Tools for Analytics\\datafile\\AZscrape.csv'\n",
    "start_entry=48001\n",
    "end_entry=63000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Use ISBN 10 to scrape book descriptions</h3>\n",
    "User Agent Code - Refer https://www.scrapehero.com/how-to-fake-and-rotate-user-agents-using-python-3/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "def amazon_description(book_metadata):\n",
    "    \n",
    "    import random\n",
    "    import time\n",
    "    \n",
    "    #New columns that will be added to book_metadata\n",
    "    book_descriptions=list()\n",
    "    book_price=list()\n",
    "    book_rating=list()\n",
    "    \n",
    "    user_agent_list = [\n",
    "           #Chrome\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 5.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "            #Firefox\n",
    "            'Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1)',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (Windows NT 6.2; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0; Trident/5.0)',\n",
    "            'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Win64; x64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)',\n",
    "            'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)',\n",
    "            'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729)'\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    book_metadata['Description']=''\n",
    "    book_metadata['Price']=''\n",
    "    book_metadata['Rating']=''\n",
    "    for i in range(len(book_metadata)):\n",
    "        \n",
    "        #User Agents to prevent bot detection\n",
    "        user_agent=random.choice(user_agent_list)\n",
    "        book_isbn=book_metadata['ASIN'].iloc[i]\n",
    "        \n",
    "        print(book_isbn)\n",
    "        base_url = \"https://www.amazon.com/s/ref=nb_sb_noss?url=search-alias%3Dstripbooks-intl-ship&field-keywords=\"\n",
    "        url=base_url+book_isbn\n",
    "        print(url)\n",
    "        headers={'User-Agent':user_agent}\n",
    "        book_response=requests.get(url,headers=headers)\n",
    "        if book_response.status_code != 200:\n",
    "            print(\"Getting Book Details Failed\")\n",
    "            return None\n",
    "        else:\n",
    "            result_page=bs(book_response.content,'lxml')\n",
    "            all_book_a_tags=result_page.find(\"a\",class_=\"a-link-normal s-access-detail-page s-color-twister-title-link a-text-normal\")\n",
    "            try:\n",
    "                book_url=all_book_a_tags.get(\"href\")\n",
    "                description,price,rating=get_book_description(book_url,user_agent_list)\n",
    "            except: \n",
    "                continue\n",
    "            print(description,price,rating)\n",
    "#             book_descriptions.append(description)\n",
    "#             book_price.append(price)\n",
    "#             book_rating.append(rating)\n",
    "        book_metadata['Description'].iloc[i]=description\n",
    "        book_metadata['Price'].iloc[i]=price\n",
    "        book_metadata['Rating'].iloc[i]=rating\n",
    "        book_metadata.to_csv(my_csvfile,encoding='utf-8') #save data after each query\n",
    "#     book_metadata['Description']=book_descriptions\n",
    "#     book_metadata['Price']=book_price\n",
    "#     book_metadata['Rating']=book_rating\n",
    "    \n",
    "    return book_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_book_description(url,user_agent_list):\n",
    "    book_description=''\n",
    "    book_rating=''\n",
    "    book_price=''\n",
    "    print(url)\n",
    "    #User Agents to prevent bot detection\n",
    "    user_agent = random.choice(user_agent_list)\n",
    "    headers = {'User-Agent': user_agent}\n",
    "    \n",
    "    #Throttling to spoof the server into believe these are generated by users\n",
    "    time.sleep(7)\n",
    "    \n",
    "    book_description_response=requests.get(url,headers=headers)\n",
    "    if book_description_response.status_code!=200:\n",
    "        print(\"Error in scraping description\")\n",
    "        return None\n",
    "    else:\n",
    "        book_page=bs(book_description_response.content,\"lxml\")\n",
    "        a1=book_page.find('div',{'id':'a-page'})\n",
    "        a2=a1.find('div',class_='book en_US').find('div',class_='a-container').find('div',{'id':'centerCol'})\n",
    "        try:\n",
    "            book_description=a2.find('div',{'id':'bookDescription_feature_div'}).find('noscript').find('div').get_text()\n",
    "        except:\n",
    "            book_description=np.NAN\n",
    "        try:\n",
    "            book_rating=a2.find('div',{'id':'averageCustomerReviews_feature_div'}).find('span',class_='a-declarative').find('span',{'id':'acrPopover'}).find('span',class_='a-declarative').find('a').find('i').find('span').get_text().split()[0]    \n",
    "        except:\n",
    "            book_rating=np.NAN\n",
    "        try:\n",
    "            book_price=a2.find('div',{'id':'MediaMatrix'}).find('div').find('div',{'id':'tmmSwatches'}).find('ul').find('li',class_='swatchElement selected').find('span').find('span').find('span').find('span',class_='a-color-base').find('span').get_text().strip()\n",
    "        except:\n",
    "            book_price=np.NAN\n",
    "        return book_description,book_price,book_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Combine in all AZscrape batches 1-7</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path_dir = r'C:\\Users\\sanjayshah\\MSBA Coursework\\Tools for Analytics\\datafile'\n",
    "file_names = ['batch1.csv', 'batch2.csv', 'batch3.csv', 'batch4.csv', 'batch5.csv', 'batch6.csv', 'batch7.csv']\n",
    "file_name_out = 'df_processed.csv'\n",
    "path_output = os.path.join(path_dir, file_name_out)\n",
    "fout = open(path_output, 'w', encoding='utf-8')\n",
    "\n",
    "for batch in file_names:\n",
    "    file_input = os.path.join(path_dir,batch)\n",
    "    fin = open(file_input,'r',encoding='utf-8')\n",
    "    for line in fin:\n",
    "        fout.write(line)\n",
    "fin.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Read in df_processed</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "patha =  r'/Users/sanjayshah/Downloads/Tools_Analytics-master/df_processed.csv'\n",
    "with open(patha):\n",
    "    df=pd.read_csv(patha)\n",
    "df = df.dropna(how='any',axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> convert df['Rating'] values to floats and strings to 0's</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ratings_to_floats(df):\n",
    "    import re\n",
    "    for i in df['Rating']:\n",
    "        i = i.strip()\n",
    "        m = bool(re.search('[a-zA-Z]',i))\n",
    "        if i =='' or m==True:\n",
    "            i='0.0'\n",
    "        i = float(i)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>convert df['Prices'] values to float</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prices_to_floats(df):\n",
    "    import re\n",
    "    for i in df['Price']:\n",
    "        i=i[1:]\n",
    "        i=float(i)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Adding Word Cloud Segment</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color='red'>Please note</font> : This code has been tested on a subset</h3>\n",
    "\n",
    "<h3>Remove the following words -</h3>\n",
    "<li>Short Words</li>\n",
    "<li>Redundant Words that appear in all descriptions</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "#MIN_LENGTH and DELETE_WORDS will need to be updated once we identify the concerned words.\n",
    "\n",
    "MIN_LENGTH=5\n",
    "DELETE_WORDS=[]\n",
    "\n",
    "def remove_words(text_string,DELETE_WORDS=DELETE_WORDS):\n",
    "    for word in DELETE_WORDS:\n",
    "        text_string = text_string.replace(word,' ')\n",
    "    return text_string\n",
    "\n",
    "\n",
    "def remove_short_words(text_string,min_length = MIN_LENGTH):\n",
    "    word_list = text_string.split()\n",
    "    for word in word_list:\n",
    "        if len(word) < min_length:\n",
    "            text_string = text_string.replace(' '+word+' ',' ',1)\n",
    "    return text_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize data\n",
    "We're trying to group data into the following buckets based on the rating the book has been assigned\n",
    "Group 1 : Ratings 5 - 4.5\n",
    "Group 2 : Ratings 4.5 - 4\n",
    "Group 3 : Ratings 4 - 3.5\n",
    "Group 4 : Ratings 3.5 - 3\n",
    "Group 5 : Ratings 3 - 2.5\n",
    "Group 0 : Irrelevant to the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorize_data(df):\n",
    "    \n",
    "    #This list stores all the categories\n",
    "    category_list=list()\n",
    "\n",
    "    \n",
    "    #Assign categories to each book\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if df['Rating'].iloc[i]>='4.5':\n",
    "            category_list.append(1)\n",
    "        elif df['Rating'].iloc[i]<'4.5' and df['Rating'].iloc[i]>='4':\n",
    "            category_list.append(2)\n",
    "        elif df['Rating'].iloc[i]<'4' and df['Rating'].iloc[i]>='3.5':\n",
    "            category_list.append(3)\n",
    "        elif df['Rating'].iloc[i]<'3.5' and df['Rating'].iloc[i]>='3':\n",
    "            category_list.append(4)\n",
    "        elif df['Rating'].iloc[i]<'3' and df['Rating'].iloc[i]>='2.5':\n",
    "            category_list.append(5)\n",
    "        else:\n",
    "            category_list.append(0)\n",
    "\n",
    "    #Add categories to the DF\n",
    "    df['Category']=category_list\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Code to aggregate text per rating</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate_text(temp):\n",
    "    x=''\n",
    "    for i in range(len(temp)):\n",
    "        x=x+' '+temp['Description'].iloc[i]\n",
    "    return x.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Control Loop</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "book_mask = np.array(Image.open(\"book.png\"))\n",
    "\n",
    "df = pd.read_csv('file1.csv')\n",
    "df=df.dropna(how='any',axis=0)\n",
    "\n",
    "COL_NUM = 2\n",
    "ROW_NUM = 3\n",
    "fig, axes = plt.subplots(ROW_NUM, COL_NUM, figsize=(15,15))\n",
    "\n",
    "\n",
    "\n",
    "df=categorize_data(df)\n",
    "\n",
    "#These two lists are for LSI Modeling\n",
    "rating_list=list()\n",
    "rating_description=list()\n",
    "\n",
    "#Please refer to LSI Modeling.ipynb for more details. Code needs to be integrated.\n",
    "\n",
    "for i in sorted(df['Category'].unique()):\n",
    "    temp=df[df['Category']==i]\n",
    "    text=aggregate_text(temp)\n",
    "    text=remove_words(text)\n",
    "    text=remove_short_words(text)\n",
    "    rating_list.append(i)\n",
    "    rating_description.append(text)\n",
    "    ax = axes[i//2, i%2] \n",
    "    ax.set_title(i)\n",
    "    wordcloud = WordCloud(stopwords=STOPWORDS,background_color='white',width=1200,height=1000,max_words=30,contour_width=20,mask=book_mask,contour_color='black').generate(text)\n",
    "    ax.imshow(wordcloud)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
