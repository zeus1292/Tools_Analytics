{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LovelyCheuk/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('file2_lily.csv',error_bad_lines=False);\n",
    "data = data.dropna(how='any',axis=0)\n",
    "data_text = data[['Description']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Part road-trip tale, part travelogue of lost ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you're making the leap from SAP BW to SAP ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The first collection of poetry by the New Yor...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"This is a compassionate look at poverty, har...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Barrie Watson has been a virtual shut-in all ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Imagine losing a loved one in the public eye....</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Gospel of John is the most deeply spiritu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>There once were seven very BAD cats...Seven c...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A New York Times BestsellerGet the recipes ev...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bruce the bear likes to keep to himself. That...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Description  index\n",
       "1    Part road-trip tale, part travelogue of lost ...      1\n",
       "2    If you're making the leap from SAP BW to SAP ...      2\n",
       "4    The first collection of poetry by the New Yor...      4\n",
       "6    \"This is a compassionate look at poverty, har...      6\n",
       "7    Barrie Watson has been a virtual shut-in all ...      7\n",
       "8    Imagine losing a loved one in the public eye....      8\n",
       "9    The Gospel of John is the most deeply spiritu...      9\n",
       "10   There once were seven very BAD cats...Seven c...     10\n",
       "17   A New York Times BestsellerGet the recipes ev...     17\n",
       "18   Bruce the bear likes to keep to himself. That...     18"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Part road-trip tale, part travelogue of lost and found landscapes, all good-natured natural history, Mariposa Road tracks Bob Pyle’s journey across the United States as he races against the calendarin his search for as many of the 800 American butterflies as he can find.\\xa0Like Pyle’s classic Chasing Monarchs, Mariposa Road recounts his adventures, high and low, in tracking down butterflies in his own low-tech, individual way. Accompanied by Marsha, his cottonwood-limb butterfly net; Powdermilk, his 1982 Honda Civic with 345,000 miles on the odometer; and the small Leitz binoculars he has carried for more than thirty years, Bob ventured out in a series of remarkable trips from his Northwest home.\\xa0From the California coastline in company with overwintering monarchs to the Far Northern tundra in pursuit of mysterious sulphurs and arctics; from the zebras and daggerwings of the Everglades to the leafwings, bluewings, and border rarities of the lower Rio Grande; from Graceland to ranchland and Kauai to Key West, these intimate encounters with the land, its people,\\xa0and its fading fauna are wholly original. At turns whimsical, witty, informative, and inspirational, Mariposa Road\\xa0is an\\xa0extraordinary journey of discovery that\\xa0leads the reader ever farther into butterfly country and\\xa0deeper into the heart of the naturalist.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents['Description'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/LovelyCheuk/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['', 'Part', 'road-trip', 'tale,', 'part', 'travelogue', 'of', 'lost', 'and', 'found', 'landscapes,', 'all', 'good-natured', 'natural', 'history,', 'Mariposa', 'Road', 'tracks', 'Bob', 'Pyle’s', 'journey', 'across', 'the', 'United', 'States', 'as', 'he', 'races', 'against', 'the', 'calendarin', 'his', 'search', 'for', 'as', 'many', 'of', 'the', '800', 'American', 'butterflies', 'as', 'he', 'can', 'find.\\xa0Like', 'Pyle’s', 'classic', 'Chasing', 'Monarchs,', 'Mariposa', 'Road', 'recounts', 'his', 'adventures,', 'high', 'and', 'low,', 'in', 'tracking', 'down', 'butterflies', 'in', 'his', 'own', 'low-tech,', 'individual', 'way.', 'Accompanied', 'by', 'Marsha,', 'his', 'cottonwood-limb', 'butterfly', 'net;', 'Powdermilk,', 'his', '1982', 'Honda', 'Civic', 'with', '345,000', 'miles', 'on', 'the', 'odometer;', 'and', 'the', 'small', 'Leitz', 'binoculars', 'he', 'has', 'carried', 'for', 'more', 'than', 'thirty', 'years,', 'Bob', 'ventured', 'out', 'in', 'a', 'series', 'of', 'remarkable', 'trips', 'from', 'his', 'Northwest', 'home.\\xa0From', 'the', 'California', 'coastline', 'in', 'company', 'with', 'overwintering', 'monarchs', 'to', 'the', 'Far', 'Northern', 'tundra', 'in', 'pursuit', 'of', 'mysterious', 'sulphurs', 'and', 'arctics;', 'from', 'the', 'zebras', 'and', 'daggerwings', 'of', 'the', 'Everglades', 'to', 'the', 'leafwings,', 'bluewings,', 'and', 'border', 'rarities', 'of', 'the', 'lower', 'Rio', 'Grande;', 'from', 'Graceland', 'to', 'ranchland', 'and', 'Kauai', 'to', 'Key', 'West,', 'these', 'intimate', 'encounters', 'with', 'the', 'land,', 'its', 'people,\\xa0and', 'its', 'fading', 'fauna', 'are', 'wholly', 'original.', 'At', 'turns', 'whimsical,', 'witty,', 'informative,', 'and', 'inspirational,', 'Mariposa', 'Road\\xa0is', 'an\\xa0extraordinary', 'journey', 'of', 'discovery', 'that\\xa0leads', 'the', 'reader', 'ever', 'farther', 'into', 'butterfly', 'country', 'and\\xa0deeper', 'into', 'the', 'heart', 'of', 'the', 'naturalist.']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['road', 'trip', 'tale', 'travelogu', 'lose', 'landscap', 'good', 'natur', 'natur', 'histori', 'mariposa', 'road', 'track', 'pyle', 'journey', 'unit', 'state', 'race', 'calendarin', 'search', 'american', 'butterfli', 'like', 'pyle', 'classic', 'chase', 'monarch', 'mariposa', 'road', 'recount', 'adventur', 'high', 'track', 'butterfli', 'tech', 'individu', 'accompani', 'marsha', 'cottonwood', 'limb', 'butterfli', 'powdermilk', 'honda', 'civic', 'mile', 'odomet', 'small', 'leitz', 'binocular', 'carri', 'thirti', 'year', 'ventur', 'seri', 'remark', 'trip', 'northwest', 'home', 'california', 'coastlin', 'compani', 'overwint', 'monarch', 'northern', 'tundra', 'pursuit', 'mysteri', 'sulphur', 'arctic', 'zebra', 'daggerw', 'everglad', 'leafw', 'bluew', 'border', 'rariti', 'lower', 'grand', 'graceland', 'ranchland', 'kauai', 'west', 'intim', 'encount', 'land', 'peopl', 'fade', 'fauna', 'wholli', 'origin', 'turn', 'whimsic', 'witti', 'inform', 'inspir', 'mariposa', 'road', 'extraordinari', 'journey', 'discoveri', 'lead', 'reader', 'farther', 'butterfli', 'countri', 'deeper', 'heart', 'naturalist']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 1].values[0][0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_docs = documents['Description'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     [road, trip, tale, travelogu, lose, landscap, ...\n",
       "2     [make, leap, hana, book, indispens, companion,...\n",
       "4     [collect, poetri, york, time, bestsel, author,...\n",
       "6     [compassion, look, poverti, hard, choic, defen...\n",
       "7     [barri, watson, virtual, shut, life, move, sou...\n",
       "8     [imagin, lose, love, public, media, frenzi, en...\n",
       "9     [gospel, john, deepli, spiritu, gospel, write,...\n",
       "10    [seven, cat, seven, cat, probabl, seven, cat, ...\n",
       "17    [york, time, bestsellerget, recip, talk, handi...\n",
       "18    [bruce, bear, like, egg, hard, boil, goos, egg...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = documents['Description'].map(preprocess)\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 accompani\n",
      "1 adventur\n",
      "2 american\n",
      "3 arctic\n",
      "4 binocular\n",
      "5 bluew\n",
      "6 border\n",
      "7 butterfli\n",
      "8 calendarin\n",
      "9 california\n",
      "10 carri\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each document we create a dictionary reporting how many\n",
    "words and how many times those words appear. Save this to ‘bow_corpus’, then check our selected document earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1),\n",
       " (10, 1),\n",
       " (11, 2),\n",
       " (12, 1),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 2),\n",
       " (17, 1),\n",
       " (18, 1),\n",
       " (19, 1),\n",
       " (20, 1),\n",
       " (21, 1),\n",
       " (22, 1),\n",
       " (23, 1),\n",
       " (24, 1),\n",
       " (25, 1),\n",
       " (26, 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 0 (\"adventur\") appears 1 time.\n",
      "Word 1 (\"american\") appears 1 time.\n",
      "Word 2 (\"classic\") appears 1 time.\n",
      "Word 3 (\"countri\") appears 1 time.\n",
      "Word 4 (\"extraordinari\") appears 1 time.\n",
      "Word 5 (\"good\") appears 1 time.\n",
      "Word 6 (\"heart\") appears 1 time.\n",
      "Word 7 (\"high\") appears 1 time.\n",
      "Word 8 (\"histori\") appears 1 time.\n",
      "Word 9 (\"home\") appears 1 time.\n",
      "Word 10 (\"inspir\") appears 1 time.\n",
      "Word 11 (\"journey\") appears 2 time.\n",
      "Word 12 (\"lead\") appears 1 time.\n",
      "Word 13 (\"like\") appears 1 time.\n",
      "Word 14 (\"lose\") appears 1 time.\n",
      "Word 15 (\"mysteri\") appears 1 time.\n",
      "Word 16 (\"natur\") appears 2 time.\n",
      "Word 17 (\"origin\") appears 1 time.\n",
      "Word 18 (\"peopl\") appears 1 time.\n",
      "Word 19 (\"reader\") appears 1 time.\n",
      "Word 20 (\"search\") appears 1 time.\n",
      "Word 21 (\"seri\") appears 1 time.\n",
      "Word 22 (\"small\") appears 1 time.\n",
      "Word 23 (\"state\") appears 1 time.\n",
      "Word 24 (\"tale\") appears 1 time.\n",
      "Word 25 (\"turn\") appears 1 time.\n",
      "Word 26 (\"year\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_0 = bow_corpus[0]\n",
    "\n",
    "for i in range(len(bow_doc_0)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_0[i][0], \n",
    "                                                     dictionary[bow_doc_0[i][0]], \n",
    "                                                     bow_doc_0[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.1896817565175649),\n",
      " (1, 0.13616465623012936),\n",
      " (2, 0.1815469917216657),\n",
      " (3, 0.1777799590017366),\n",
      " (4, 0.19877564986109572),\n",
      " (5, 0.1777799590017366),\n",
      " (6, 0.1777799590017366),\n",
      " (7, 0.17075613215210664),\n",
      " (8, 0.14770983022422038),\n",
      " (9, 0.15837625970208172),\n",
      " (10, 0.13616465623012936),\n",
      " (11, 0.3793635130351298),\n",
      " (12, 0.1896817565175649),\n",
      " (13, 0.11893599809069934),\n",
      " (14, 0.1777799590017366),\n",
      " (15, 0.1940948922144773),\n",
      " (16, 0.3793635130351298),\n",
      " (17, 0.16747015304561255),\n",
      " (18, 0.13616465623012936),\n",
      " (19, 0.13616465623012936),\n",
      " (20, 0.20375859519361803),\n",
      " (21, 0.18550728826012086),\n",
      " (22, 0.1896817565175649),\n",
      " (23, 0.1815469917216657),\n",
      " (24, 0.1815469917216657),\n",
      " (25, 0.16129014722003585),\n",
      " (26, 0.08593353504918798)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.059*\"time\" + 0.030*\"book\" + 0.021*\"stori\" + 0.018*\"york\" + 0.018*\"life\" + 0.018*\"author\" + 0.018*\"busi\" + 0.017*\"work\" + 0.016*\"today\" + 0.015*\"includ\"\n",
      "Topic: 1 \n",
      "Words: 0.053*\"busi\" + 0.036*\"book\" + 0.031*\"chang\" + 0.023*\"help\" + 0.023*\"start\" + 0.021*\"learn\" + 0.020*\"creat\" + 0.019*\"plan\" + 0.019*\"know\" + 0.019*\"histori\"\n",
      "Topic: 2 \n",
      "Words: 0.050*\"famili\" + 0.036*\"love\" + 0.028*\"stori\" + 0.028*\"live\" + 0.022*\"murder\" + 0.019*\"countri\" + 0.019*\"novel\" + 0.018*\"like\" + 0.017*\"life\" + 0.017*\"world\"\n",
      "Topic: 3 \n",
      "Words: 0.048*\"life\" + 0.031*\"time\" + 0.024*\"book\" + 0.021*\"world\" + 0.020*\"year\" + 0.020*\"stori\" + 0.018*\"famili\" + 0.017*\"best\" + 0.016*\"love\" + 0.015*\"york\"\n",
      "Topic: 4 \n",
      "Words: 0.073*\"stori\" + 0.032*\"write\" + 0.025*\"live\" + 0.024*\"american\" + 0.023*\"town\" + 0.023*\"take\" + 0.022*\"make\" + 0.020*\"collect\" + 0.017*\"time\" + 0.017*\"like\"\n",
      "Topic: 5 \n",
      "Words: 0.038*\"human\" + 0.037*\"book\" + 0.034*\"world\" + 0.034*\"seri\" + 0.020*\"know\" + 0.020*\"time\" + 0.018*\"year\" + 0.017*\"stori\" + 0.017*\"histori\" + 0.016*\"bestsel\"\n",
      "Topic: 6 \n",
      "Words: 0.058*\"american\" + 0.039*\"book\" + 0.033*\"america\" + 0.030*\"world\" + 0.026*\"self\" + 0.025*\"high\" + 0.024*\"true\" + 0.022*\"popular\" + 0.019*\"cultur\" + 0.017*\"centuri\"\n",
      "Topic: 7 \n",
      "Words: 0.065*\"world\" + 0.063*\"book\" + 0.021*\"year\" + 0.020*\"stori\" + 0.020*\"best\" + 0.018*\"word\" + 0.018*\"know\" + 0.017*\"time\" + 0.016*\"understand\" + 0.016*\"read\"\n",
      "Topic: 8 \n",
      "Words: 0.033*\"world\" + 0.031*\"time\" + 0.029*\"bestsel\" + 0.026*\"year\" + 0.025*\"book\" + 0.021*\"york\" + 0.021*\"author\" + 0.020*\"know\" + 0.017*\"like\" + 0.016*\"countri\"\n",
      "Topic: 9 \n",
      "Words: 0.032*\"book\" + 0.029*\"famili\" + 0.027*\"know\" + 0.024*\"help\" + 0.023*\"live\" + 0.019*\"break\" + 0.018*\"come\" + 0.017*\"discov\" + 0.016*\"learn\" + 0.016*\"find\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.023*\"busi\" + 0.021*\"plan\" + 0.019*\"build\" + 0.016*\"guid\" + 0.016*\"live\" + 0.014*\"famili\" + 0.013*\"want\" + 0.013*\"help\" + 0.013*\"start\" + 0.013*\"york\"\n",
      "Topic: 1 Word: 0.038*\"citi\" + 0.022*\"word\" + 0.019*\"grow\" + 0.019*\"murder\" + 0.018*\"figur\" + 0.016*\"seri\" + 0.016*\"illustr\" + 0.015*\"york\" + 0.014*\"year\" + 0.013*\"mysteri\"\n",
      "Topic: 2 Word: 0.022*\"beauti\" + 0.018*\"home\" + 0.017*\"like\" + 0.017*\"busi\" + 0.016*\"popular\" + 0.015*\"chang\" + 0.015*\"adventur\" + 0.015*\"discov\" + 0.014*\"hand\" + 0.014*\"grow\"\n",
      "Topic: 3 Word: 0.017*\"town\" + 0.016*\"world\" + 0.016*\"famili\" + 0.016*\"life\" + 0.014*\"kind\" + 0.014*\"countri\" + 0.013*\"mysteri\" + 0.013*\"live\" + 0.012*\"year\" + 0.012*\"past\"\n",
      "Topic: 4 Word: 0.019*\"life\" + 0.019*\"explor\" + 0.017*\"young\" + 0.017*\"scienc\" + 0.016*\"book\" + 0.016*\"best\" + 0.015*\"love\" + 0.014*\"novel\" + 0.014*\"experi\" + 0.013*\"world\"\n",
      "Topic: 5 Word: 0.042*\"book\" + 0.037*\"classic\" + 0.021*\"perfect\" + 0.019*\"hous\" + 0.018*\"self\" + 0.017*\"friend\" + 0.016*\"come\" + 0.015*\"human\" + 0.014*\"break\" + 0.014*\"read\"\n",
      "Topic: 6 Word: 0.021*\"stori\" + 0.014*\"histori\" + 0.014*\"power\" + 0.013*\"book\" + 0.012*\"import\" + 0.012*\"begin\" + 0.012*\"famili\" + 0.011*\"open\" + 0.011*\"read\" + 0.011*\"true\"\n",
      "Topic: 7 Word: 0.032*\"american\" + 0.022*\"reader\" + 0.018*\"stori\" + 0.017*\"includ\" + 0.016*\"tradit\" + 0.015*\"like\" + 0.015*\"world\" + 0.014*\"america\" + 0.013*\"book\" + 0.013*\"lead\"\n",
      "Topic: 8 Word: 0.033*\"page\" + 0.024*\"give\" + 0.022*\"life\" + 0.021*\"novel\" + 0.021*\"american\" + 0.018*\"experi\" + 0.017*\"person\" + 0.017*\"america\" + 0.017*\"take\" + 0.016*\"book\"\n",
      "Topic: 9 Word: 0.027*\"murder\" + 0.020*\"learn\" + 0.019*\"polit\" + 0.019*\"seri\" + 0.017*\"know\" + 0.015*\"star\" + 0.014*\"struggl\" + 0.014*\"origin\" + 0.013*\"detail\" + 0.013*\"human\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['road',\n",
       " 'trip',\n",
       " 'tale',\n",
       " 'travelogu',\n",
       " 'lose',\n",
       " 'landscap',\n",
       " 'good',\n",
       " 'natur',\n",
       " 'natur',\n",
       " 'histori',\n",
       " 'mariposa',\n",
       " 'road',\n",
       " 'track',\n",
       " 'pyle',\n",
       " 'journey',\n",
       " 'unit',\n",
       " 'state',\n",
       " 'race',\n",
       " 'calendarin',\n",
       " 'search',\n",
       " 'american',\n",
       " 'butterfli',\n",
       " 'like',\n",
       " 'pyle',\n",
       " 'classic',\n",
       " 'chase',\n",
       " 'monarch',\n",
       " 'mariposa',\n",
       " 'road',\n",
       " 'recount',\n",
       " 'adventur',\n",
       " 'high',\n",
       " 'track',\n",
       " 'butterfli',\n",
       " 'tech',\n",
       " 'individu',\n",
       " 'accompani',\n",
       " 'marsha',\n",
       " 'cottonwood',\n",
       " 'limb',\n",
       " 'butterfli',\n",
       " 'powdermilk',\n",
       " 'honda',\n",
       " 'civic',\n",
       " 'mile',\n",
       " 'odomet',\n",
       " 'small',\n",
       " 'leitz',\n",
       " 'binocular',\n",
       " 'carri',\n",
       " 'thirti',\n",
       " 'year',\n",
       " 'ventur',\n",
       " 'seri',\n",
       " 'remark',\n",
       " 'trip',\n",
       " 'northwest',\n",
       " 'home',\n",
       " 'california',\n",
       " 'coastlin',\n",
       " 'compani',\n",
       " 'overwint',\n",
       " 'monarch',\n",
       " 'northern',\n",
       " 'tundra',\n",
       " 'pursuit',\n",
       " 'mysteri',\n",
       " 'sulphur',\n",
       " 'arctic',\n",
       " 'zebra',\n",
       " 'daggerw',\n",
       " 'everglad',\n",
       " 'leafw',\n",
       " 'bluew',\n",
       " 'border',\n",
       " 'rariti',\n",
       " 'lower',\n",
       " 'grand',\n",
       " 'graceland',\n",
       " 'ranchland',\n",
       " 'kauai',\n",
       " 'west',\n",
       " 'intim',\n",
       " 'encount',\n",
       " 'land',\n",
       " 'peopl',\n",
       " 'fade',\n",
       " 'fauna',\n",
       " 'wholli',\n",
       " 'origin',\n",
       " 'turn',\n",
       " 'whimsic',\n",
       " 'witti',\n",
       " 'inform',\n",
       " 'inspir',\n",
       " 'mariposa',\n",
       " 'road',\n",
       " 'extraordinari',\n",
       " 'journey',\n",
       " 'discoveri',\n",
       " 'lead',\n",
       " 'reader',\n",
       " 'farther',\n",
       " 'butterfli',\n",
       " 'countri',\n",
       " 'deeper',\n",
       " 'heart',\n",
       " 'naturalist']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.5001440644264221\t \n",
      "Topic: 0.053*\"busi\" + 0.036*\"book\" + 0.031*\"chang\" + 0.023*\"help\" + 0.023*\"start\" + 0.021*\"learn\" + 0.020*\"creat\" + 0.019*\"plan\" + 0.019*\"know\" + 0.019*\"histori\"\n",
      "\n",
      "Score: 0.4527895450592041\t \n",
      "Topic: 0.032*\"book\" + 0.029*\"famili\" + 0.027*\"know\" + 0.024*\"help\" + 0.023*\"live\" + 0.019*\"break\" + 0.018*\"come\" + 0.017*\"discov\" + 0.016*\"learn\" + 0.016*\"find\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[1]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.5549411773681641\t \n",
      "Topic: 0.027*\"murder\" + 0.020*\"learn\" + 0.019*\"polit\" + 0.019*\"seri\" + 0.017*\"know\" + 0.015*\"star\" + 0.014*\"struggl\" + 0.014*\"origin\" + 0.013*\"detail\" + 0.013*\"human\"\n",
      "\n",
      "Score: 0.2296331375837326\t \n",
      "Topic: 0.019*\"life\" + 0.019*\"explor\" + 0.017*\"young\" + 0.017*\"scienc\" + 0.016*\"book\" + 0.016*\"best\" + 0.015*\"love\" + 0.014*\"novel\" + 0.014*\"experi\" + 0.013*\"world\"\n",
      "\n",
      "Score: 0.17424091696739197\t \n",
      "Topic: 0.032*\"american\" + 0.022*\"reader\" + 0.018*\"stori\" + 0.017*\"includ\" + 0.016*\"tradit\" + 0.015*\"like\" + 0.015*\"world\" + 0.014*\"america\" + 0.013*\"book\" + 0.013*\"lead\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[1]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
