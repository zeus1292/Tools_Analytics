{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LovelyCheuk/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('file2_lily.csv', error_bad_lines=False);\n",
    "data_text = data[['Description']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Preschooler’s Handbook introduces 18 basi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Part road-trip tale, part travelogue of lost ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you're making the leap from SAP BW to SAP ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The first collection of poetry by the New Yor...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"This is a compassionate look at poverty, har...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Barrie Watson has been a virtual shut-in all ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Imagine losing a loved one in the public eye....</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Gospel of John is the most deeply spiritu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>There once were seven very BAD cats...Seven c...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A New York Times BestsellerGet the recipes ev...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bruce the bear likes to keep to himself. That...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The apostle Paul wrote his most personal lett...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The magic and suspense of Graceling meet the ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A NEW YORK TIMES BESTSELLERAS SEEN ON NATIONA...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>This is a new book from the Pacific Northwes...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What could be better than standing on top of ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Spencer Plain is ready to help build a new Be...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Akiti the hunter is riveting and exciting tal...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Traveling to 41 countries in 2015 with a back...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>You don't have to be an entrepreneur to think...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>In the tradition of Ian Frazier's Great Plain...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>There's something rotten in the state of Ohio...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>NaN</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>NaN</td>\n",
       "      <td>971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>NaN</td>\n",
       "      <td>972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>NaN</td>\n",
       "      <td>973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>NaN</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>NaN</td>\n",
       "      <td>976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>NaN</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>NaN</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>NaN</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>NaN</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>NaN</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>NaN</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>NaN</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>NaN</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>NaN</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>NaN</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>NaN</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>NaN</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>NaN</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>NaN</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>NaN</td>\n",
       "      <td>991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>NaN</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>NaN</td>\n",
       "      <td>993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>NaN</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>When Holly White’s fiancé cancels their Chris...</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description  index\n",
       "0     The Preschooler’s Handbook introduces 18 basi...      0\n",
       "1     Part road-trip tale, part travelogue of lost ...      1\n",
       "2     If you're making the leap from SAP BW to SAP ...      2\n",
       "3                                                  NaN      3\n",
       "4     The first collection of poetry by the New Yor...      4\n",
       "5                                                  NaN      5\n",
       "6     \"This is a compassionate look at poverty, har...      6\n",
       "7     Barrie Watson has been a virtual shut-in all ...      7\n",
       "8     Imagine losing a loved one in the public eye....      8\n",
       "9     The Gospel of John is the most deeply spiritu...      9\n",
       "10    There once were seven very BAD cats...Seven c...     10\n",
       "11                                                 NaN     11\n",
       "12                                                 NaN     12\n",
       "13                                                 NaN     13\n",
       "14                                                 NaN     14\n",
       "15                                                 NaN     15\n",
       "16                                                 NaN     16\n",
       "17    A New York Times BestsellerGet the recipes ev...     17\n",
       "18    Bruce the bear likes to keep to himself. That...     18\n",
       "19    The apostle Paul wrote his most personal lett...     19\n",
       "20    The magic and suspense of Graceling meet the ...     20\n",
       "21    A NEW YORK TIMES BESTSELLERAS SEEN ON NATIONA...     21\n",
       "22     This is a new book from the Pacific Northwes...     22\n",
       "23    What could be better than standing on top of ...     23\n",
       "24    Spencer Plain is ready to help build a new Be...     24\n",
       "25    Akiti the hunter is riveting and exciting tal...     25\n",
       "26    Traveling to 41 countries in 2015 with a back...     26\n",
       "27    You don't have to be an entrepreneur to think...     27\n",
       "28    In the tradition of Ian Frazier's Great Plain...     28\n",
       "29    There's something rotten in the state of Ohio...     29\n",
       "..                                                 ...    ...\n",
       "970                                                NaN    970\n",
       "971                                                NaN    971\n",
       "972                                                NaN    972\n",
       "973                                                NaN    973\n",
       "974                                                NaN    974\n",
       "975                                                NaN    975\n",
       "976                                                NaN    976\n",
       "977                                                NaN    977\n",
       "978                                                NaN    978\n",
       "979                                                NaN    979\n",
       "980                                                NaN    980\n",
       "981                                                NaN    981\n",
       "982                                                NaN    982\n",
       "983                                                NaN    983\n",
       "984                                                NaN    984\n",
       "985                                                NaN    985\n",
       "986                                                NaN    986\n",
       "987                                                NaN    987\n",
       "988                                                NaN    988\n",
       "989                                                NaN    989\n",
       "990                                                NaN    990\n",
       "991                                                NaN    991\n",
       "992                                                NaN    992\n",
       "993                                                NaN    993\n",
       "994                                                NaN    994\n",
       "995                                                NaN    995\n",
       "996   When Holly White’s fiancé cancels their Chris...    996\n",
       "997                                                NaN    997\n",
       "998                                                NaN    998\n",
       "999                                                NaN    999\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/LovelyCheuk/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['', 'When', 'Holly', 'White’s', 'fiancé', 'cancels', 'their', 'Christmas', 'Eve', 'wedding', 'with', 'less', 'than', 'two', 'weeks', 'to', 'go,', 'Holly', 'heads', 'home', 'with', 'a', 'broken', 'heart.', 'Lucky', 'for', 'her,', 'home', 'in', 'historic', 'Mistletoe,', 'Maine', 'is', 'magical', 'during', 'Christmastime―exactly', 'what', 'the', 'doctor', 'prescribed.', 'Except', 'her', 'plan', 'to', 'drown', 'her', 'troubles', 'in', 'peppermints', 'and', 'snickerdoodles', 'is', 'upended', 'when', 'local', 'grouch', 'and', 'president', 'of', 'the', 'Mistletoe', 'Historical', 'Society', 'Margaret', 'Fenwick', 'is', 'bludgeoned', 'and', 'left', 'in', 'the', 'sleigh', 'display', 'at', 'Reindeer', 'Games,', 'Holly’s', 'family', 'tree', 'farm.When', 'the', 'murder', 'weapon', 'is', 'revealed', 'as', 'one', 'of', 'the', 'wooden', 'stakes', 'used', 'to', 'identify', 'trees', 'on', 'the', 'farm,', 'Sheriff', 'Evan', 'Grey', 'turns', 'to', 'Holly’s', 'father,', 'Bud,', 'and', 'the', 'Reindeer', 'Games', 'staff.', 'And', 'it', 'doesn’t', 'help', 'that', 'Bud', 'and', 'the', 'reindeer', 'keeper', 'were', 'each', 'seen', 'arguing', 'with', 'Margaret', 'just', 'before', 'her', 'death.', 'But', 'Holly', 'knows', 'her', 'father,', 'and', 'is', 'determined', 'to', 'exonerate', 'him.The', 'jingle', 'bells', 'are', 'ringing,', 'the', 'clock', 'is', 'ticking,', 'and', 'if', 'Holly', \"doesn't\", 'watch', 'out,', \"she'll\", 'end', 'up', 'on', \"Santa's\", 'naughty', 'list', 'in', 'Twelve', 'Slays', 'of', 'Christmas,', 'Jacqueline', 'Frost’s', 'jolly', 'series', 'debut.']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['holli', 'white', 'fiancé', 'cancel', 'christma', 'wed', 'week', 'holli', 'head', 'home', 'break', 'heart', 'lucki', 'home', 'histor', 'mistleto', 'main', 'magic', 'christmastim', 'exact', 'doctor', 'prescrib', 'plan', 'drown', 'troubl', 'peppermint', 'snickerdoodl', 'upend', 'local', 'grouch', 'presid', 'mistleto', 'histor', 'societi', 'margaret', 'fenwick', 'bludgeon', 'leav', 'sleigh', 'display', 'reindeer', 'game', 'holli', 'famili', 'tree', 'farm', 'murder', 'weapon', 'reveal', 'wooden', 'stake', 'identifi', 'tree', 'farm', 'sheriff', 'evan', 'grey', 'turn', 'holli', 'father', 'reindeer', 'game', 'staff', 'help', 'reindeer', 'keeper', 'see', 'argu', 'margaret', 'death', 'holli', 'know', 'father', 'determin', 'exoner', 'jingl', 'bell', 'ring', 'clock', 'tick', 'holli', 'watch', 'santa', 'naughti', 'list', 'slay', 'christma', 'jacquelin', 'frost', 'jolli', 'seri', 'debut']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 996].values[0][0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "decoding to str: need a bytes-like object, float found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d38dfe969069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocessed_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclientSocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserverName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserverPort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LovelyCheuk/anaconda/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   2996\u001b[0m         \"\"\"\n\u001b[1;32m   2997\u001b[0m         new_values = super(Series, self)._map_values(\n\u001b[0;32m-> 2998\u001b[0;31m             arg, na_action=na_action)\n\u001b[0m\u001b[1;32m   2999\u001b[0m         return self._constructor(new_values,\n\u001b[1;32m   3000\u001b[0m                                  index=self.index).__finalize__(self)\n",
      "\u001b[0;32m/Users/LovelyCheuk/anaconda/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-ba3b0a751b71>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTOPWORDS\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatize_stemming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LovelyCheuk/anaconda/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36msimple_preprocess\u001b[0;34m(doc, deacc, min_len, max_len)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \"\"\"\n\u001b[1;32m    300\u001b[0m     tokens = [\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeacc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmin_len\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     ]\n",
      "\u001b[0;32m/Users/LovelyCheuk/anaconda/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(text, lowercase, deacc, encoding, errors, to_lower, lower)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \"\"\"\n\u001b[1;32m    251\u001b[0m     \u001b[0mlowercase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlowercase\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mto_lower\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LovelyCheuk/anaconda/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36many2unicode\u001b[0;34m(text, encoding, errors)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: decoding to str: need a bytes-like object, float found"
     ]
    }
   ],
   "source": [
    "processed_docs = documents['Description'].map(preprocess)\n",
    "clientSocket.sendto(message.encode(),(serverName, serverPort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
