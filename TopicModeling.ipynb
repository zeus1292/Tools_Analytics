{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LovelyCheuk/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('file2_lily.csv',error_bad_lines=False);\n",
    "data = data.dropna(how='any',axis=0)\n",
    "data_text = data[['Description']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Part road-trip tale, part travelogue of lost ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you're making the leap from SAP BW to SAP ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The first collection of poetry by the New Yor...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"This is a compassionate look at poverty, har...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Barrie Watson has been a virtual shut-in all ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Imagine losing a loved one in the public eye....</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Gospel of John is the most deeply spiritu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>There once were seven very BAD cats...Seven c...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A New York Times BestsellerGet the recipes ev...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bruce the bear likes to keep to himself. That...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The apostle Paul wrote his most personal lett...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The magic and suspense of Graceling meet the ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A NEW YORK TIMES BESTSELLERAS SEEN ON NATIONA...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>This is a new book from the Pacific Northwes...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What could be better than standing on top of ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Spencer Plain is ready to help build a new Be...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Akiti the hunter is riveting and exciting tal...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Traveling to 41 countries in 2015 with a back...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>You don't have to be an entrepreneur to think...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>In the tradition of Ian Frazier's Great Plain...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>There's something rotten in the state of Ohio...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>brand new book, never used.</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Throughout much of the world, night skies are...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>In the tradition of Agent Zigzag comes this b...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>BRAND NEW, Exactly same ISBN as listed, Pleas...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Xlibris author Jordan P. Castro has seen his ...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>An award-winning Northwestern University psyc...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Can you hide a secret with the whole world wa...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Sven Carter—part boy, part robot—is back and ...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Meet the ites! From Aaron to Zoram, get to kn...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>There's something about asking for Impossible...</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Bylines is the latest title from award-winnin...</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>\"The foremost authority on Puerto Rican cooki...</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>A quote book like no other, this thought-prov...</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>An authoritative and entertaining exploration...</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>The author of the hugely successful and peren...</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Three classic graphic novels in one deluxe ha...</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Hi. In your hands, right now, you hold the cu...</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>“Non-formulaic, eye-opening, deeply-researche...</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>The 2013 James Beard Foundation Cookbook of t...</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>Oscar Mandinga, great-grandchild of the found...</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>NEW YORK TIMES BESTSELLER • J. R. Ward return...</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>A neuroscientific perspective on the mind–bod...</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>A hilarious companion to I Wanna Iguana. Ever...</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>2017 Audie Winner: Inspirational/Faith-Based ...</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Oceanic explorers Dirk Pitt and Al Giordino f...</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>A stunning picture book about the power of im...</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>How skirting the law once defined America’s r...</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Named a Best Book of Fall by The Washington P...</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>In this delightfully charming teen spin on Yo...</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>This design history of Southwestern Indian br...</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>Just as he demystified the soil food web in h...</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>“No two exit experiences are exactly alike. S...</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>The extraordinary story of the small Vermont ...</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>Use this guide to weed out what dyslexia mean...</td>\n",
       "      <td>852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>The essential guide to selling your business-...</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>Winner of the Cundill History Prize A viscera...</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>Audrey Hepburn's status as a global style ico...</td>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>Book by Konkle, Marsena</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>When Holly White’s fiancé cancels their Chris...</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description  index\n",
       "1     Part road-trip tale, part travelogue of lost ...      1\n",
       "2     If you're making the leap from SAP BW to SAP ...      2\n",
       "4     The first collection of poetry by the New Yor...      4\n",
       "6     \"This is a compassionate look at poverty, har...      6\n",
       "7     Barrie Watson has been a virtual shut-in all ...      7\n",
       "8     Imagine losing a loved one in the public eye....      8\n",
       "9     The Gospel of John is the most deeply spiritu...      9\n",
       "10    There once were seven very BAD cats...Seven c...     10\n",
       "17    A New York Times BestsellerGet the recipes ev...     17\n",
       "18    Bruce the bear likes to keep to himself. That...     18\n",
       "19    The apostle Paul wrote his most personal lett...     19\n",
       "20    The magic and suspense of Graceling meet the ...     20\n",
       "21    A NEW YORK TIMES BESTSELLERAS SEEN ON NATIONA...     21\n",
       "22     This is a new book from the Pacific Northwes...     22\n",
       "23    What could be better than standing on top of ...     23\n",
       "24    Spencer Plain is ready to help build a new Be...     24\n",
       "25    Akiti the hunter is riveting and exciting tal...     25\n",
       "26    Traveling to 41 countries in 2015 with a back...     26\n",
       "27    You don't have to be an entrepreneur to think...     27\n",
       "28    In the tradition of Ian Frazier's Great Plain...     28\n",
       "29    There's something rotten in the state of Ohio...     29\n",
       "33                         brand new book, never used.     33\n",
       "36    Throughout much of the world, night skies are...     36\n",
       "37    In the tradition of Agent Zigzag comes this b...     37\n",
       "38    BRAND NEW, Exactly same ISBN as listed, Pleas...     38\n",
       "39    Xlibris author Jordan P. Castro has seen his ...     39\n",
       "40    An award-winning Northwestern University psyc...     40\n",
       "42    Can you hide a secret with the whole world wa...     42\n",
       "43    Sven Carter—part boy, part robot—is back and ...     43\n",
       "44    Meet the ites! From Aaron to Zoram, get to kn...     44\n",
       "..                                                 ...    ...\n",
       "302   There's something about asking for Impossible...    302\n",
       "303   Bylines is the latest title from award-winnin...    303\n",
       "306   \"The foremost authority on Puerto Rican cooki...    306\n",
       "307   A quote book like no other, this thought-prov...    307\n",
       "308   An authoritative and entertaining exploration...    308\n",
       "309   The author of the hugely successful and peren...    309\n",
       "310   Three classic graphic novels in one deluxe ha...    310\n",
       "312   Hi. In your hands, right now, you hold the cu...    312\n",
       "313   “Non-formulaic, eye-opening, deeply-researche...    313\n",
       "440   The 2013 James Beard Foundation Cookbook of t...    440\n",
       "459   Oscar Mandinga, great-grandchild of the found...    459\n",
       "508   NEW YORK TIMES BESTSELLER • J. R. Ward return...    508\n",
       "518   A neuroscientific perspective on the mind–bod...    518\n",
       "524   A hilarious companion to I Wanna Iguana. Ever...    524\n",
       "562   2017 Audie Winner: Inspirational/Faith-Based ...    562\n",
       "599   Oceanic explorers Dirk Pitt and Al Giordino f...    599\n",
       "638   A stunning picture book about the power of im...    638\n",
       "656   How skirting the law once defined America’s r...    656\n",
       "681   Named a Best Book of Fall by The Washington P...    681\n",
       "702   In this delightfully charming teen spin on Yo...    702\n",
       "714   This design history of Southwestern Indian br...    714\n",
       "793   Just as he demystified the soil food web in h...    793\n",
       "830   “No two exit experiences are exactly alike. S...    830\n",
       "840   The extraordinary story of the small Vermont ...    840\n",
       "852   Use this guide to weed out what dyslexia mean...    852\n",
       "863   The essential guide to selling your business-...    863\n",
       "926   Winner of the Cundill History Prize A viscera...    926\n",
       "938   Audrey Hepburn's status as a global style ico...    938\n",
       "943                            Book by Konkle, Marsena    943\n",
       "996   When Holly White’s fiancé cancels their Chris...    996\n",
       "\n",
       "[210 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/LovelyCheuk/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['', 'When', 'Holly', 'White’s', 'fiancé', 'cancels', 'their', 'Christmas', 'Eve', 'wedding', 'with', 'less', 'than', 'two', 'weeks', 'to', 'go,', 'Holly', 'heads', 'home', 'with', 'a', 'broken', 'heart.', 'Lucky', 'for', 'her,', 'home', 'in', 'historic', 'Mistletoe,', 'Maine', 'is', 'magical', 'during', 'Christmastime―exactly', 'what', 'the', 'doctor', 'prescribed.', 'Except', 'her', 'plan', 'to', 'drown', 'her', 'troubles', 'in', 'peppermints', 'and', 'snickerdoodles', 'is', 'upended', 'when', 'local', 'grouch', 'and', 'president', 'of', 'the', 'Mistletoe', 'Historical', 'Society', 'Margaret', 'Fenwick', 'is', 'bludgeoned', 'and', 'left', 'in', 'the', 'sleigh', 'display', 'at', 'Reindeer', 'Games,', 'Holly’s', 'family', 'tree', 'farm.When', 'the', 'murder', 'weapon', 'is', 'revealed', 'as', 'one', 'of', 'the', 'wooden', 'stakes', 'used', 'to', 'identify', 'trees', 'on', 'the', 'farm,', 'Sheriff', 'Evan', 'Grey', 'turns', 'to', 'Holly’s', 'father,', 'Bud,', 'and', 'the', 'Reindeer', 'Games', 'staff.', 'And', 'it', 'doesn’t', 'help', 'that', 'Bud', 'and', 'the', 'reindeer', 'keeper', 'were', 'each', 'seen', 'arguing', 'with', 'Margaret', 'just', 'before', 'her', 'death.', 'But', 'Holly', 'knows', 'her', 'father,', 'and', 'is', 'determined', 'to', 'exonerate', 'him.The', 'jingle', 'bells', 'are', 'ringing,', 'the', 'clock', 'is', 'ticking,', 'and', 'if', 'Holly', \"doesn't\", 'watch', 'out,', \"she'll\", 'end', 'up', 'on', \"Santa's\", 'naughty', 'list', 'in', 'Twelve', 'Slays', 'of', 'Christmas,', 'Jacqueline', 'Frost’s', 'jolly', 'series', 'debut.']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['holli', 'white', 'fiancé', 'cancel', 'christma', 'wed', 'week', 'holli', 'head', 'home', 'break', 'heart', 'lucki', 'home', 'histor', 'mistleto', 'main', 'magic', 'christmastim', 'exact', 'doctor', 'prescrib', 'plan', 'drown', 'troubl', 'peppermint', 'snickerdoodl', 'upend', 'local', 'grouch', 'presid', 'mistleto', 'histor', 'societi', 'margaret', 'fenwick', 'bludgeon', 'leav', 'sleigh', 'display', 'reindeer', 'game', 'holli', 'famili', 'tree', 'farm', 'murder', 'weapon', 'reveal', 'wooden', 'stake', 'identifi', 'tree', 'farm', 'sheriff', 'evan', 'grey', 'turn', 'holli', 'father', 'reindeer', 'game', 'staff', 'help', 'reindeer', 'keeper', 'see', 'argu', 'margaret', 'death', 'holli', 'know', 'father', 'determin', 'exoner', 'jingl', 'bell', 'ring', 'clock', 'tick', 'holli', 'watch', 'santa', 'naughti', 'list', 'slay', 'christma', 'jacquelin', 'frost', 'jolli', 'seri', 'debut']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 996].values[0][0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = documents['Description'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 accompani\n",
      "1 adventur\n",
      "2 american\n",
      "3 arctic\n",
      "4 binocular\n",
      "5 bluew\n",
      "6 border\n",
      "7 butterfli\n",
      "8 calendarin\n",
      "9 california\n",
      "10 carri\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(27, 1),\n",
       " (28, 2),\n",
       " (29, 2),\n",
       " (30, 1),\n",
       " (31, 1),\n",
       " (32, 1),\n",
       " (33, 1),\n",
       " (34, 1),\n",
       " (35, 4),\n",
       " (36, 1),\n",
       " (37, 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 27 (\"book\") appears 1 time.\n",
      "Word 28 (\"chang\") appears 2 time.\n",
      "Word 29 (\"detail\") appears 2 time.\n",
      "Word 30 (\"explor\") appears 1 time.\n",
      "Word 31 (\"generat\") appears 1 time.\n",
      "Word 32 (\"guid\") appears 1 time.\n",
      "Word 33 (\"includ\") appears 1 time.\n",
      "Word 34 (\"know\") appears 1 time.\n",
      "Word 35 (\"learn\") appears 4 time.\n",
      "Word 36 (\"make\") appears 1 time.\n",
      "Word 37 (\"need\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_1 = bow_corpus[1]\n",
    "\n",
    "for i in range(len(bow_doc_1)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_1[i][0], \n",
    "                                                     dictionary[bow_doc_1[i][0]], \n",
    "                                                     bow_doc_1[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.1896817565175649),\n",
      " (1, 0.13616465623012936),\n",
      " (2, 0.1815469917216657),\n",
      " (3, 0.1777799590017366),\n",
      " (4, 0.19877564986109572),\n",
      " (5, 0.1777799590017366),\n",
      " (6, 0.1777799590017366),\n",
      " (7, 0.17075613215210664),\n",
      " (8, 0.14770983022422038),\n",
      " (9, 0.15837625970208172),\n",
      " (10, 0.13616465623012936),\n",
      " (11, 0.3793635130351298),\n",
      " (12, 0.1896817565175649),\n",
      " (13, 0.11893599809069934),\n",
      " (14, 0.1777799590017366),\n",
      " (15, 0.1940948922144773),\n",
      " (16, 0.3793635130351298),\n",
      " (17, 0.16747015304561255),\n",
      " (18, 0.13616465623012936),\n",
      " (19, 0.13616465623012936),\n",
      " (20, 0.20375859519361803),\n",
      " (21, 0.18550728826012086),\n",
      " (22, 0.1896817565175649),\n",
      " (23, 0.1815469917216657),\n",
      " (24, 0.1815469917216657),\n",
      " (25, 0.16129014722003585),\n",
      " (26, 0.08593353504918798)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.059*\"time\" + 0.030*\"book\" + 0.021*\"stori\" + 0.018*\"york\" + 0.018*\"life\" + 0.018*\"author\" + 0.018*\"busi\" + 0.017*\"work\" + 0.016*\"today\" + 0.015*\"includ\"\n",
      "Topic: 1 \n",
      "Words: 0.053*\"busi\" + 0.036*\"book\" + 0.031*\"chang\" + 0.023*\"help\" + 0.023*\"start\" + 0.021*\"learn\" + 0.020*\"creat\" + 0.019*\"plan\" + 0.019*\"know\" + 0.019*\"histori\"\n",
      "Topic: 2 \n",
      "Words: 0.050*\"famili\" + 0.036*\"love\" + 0.028*\"stori\" + 0.028*\"live\" + 0.022*\"murder\" + 0.019*\"countri\" + 0.019*\"novel\" + 0.018*\"like\" + 0.017*\"life\" + 0.017*\"world\"\n",
      "Topic: 3 \n",
      "Words: 0.048*\"life\" + 0.031*\"time\" + 0.024*\"book\" + 0.021*\"world\" + 0.020*\"year\" + 0.020*\"stori\" + 0.018*\"famili\" + 0.017*\"best\" + 0.016*\"love\" + 0.015*\"york\"\n",
      "Topic: 4 \n",
      "Words: 0.073*\"stori\" + 0.032*\"write\" + 0.025*\"live\" + 0.024*\"american\" + 0.023*\"town\" + 0.023*\"take\" + 0.022*\"make\" + 0.020*\"collect\" + 0.017*\"time\" + 0.017*\"like\"\n",
      "Topic: 5 \n",
      "Words: 0.038*\"human\" + 0.037*\"book\" + 0.034*\"world\" + 0.034*\"seri\" + 0.020*\"know\" + 0.020*\"time\" + 0.018*\"year\" + 0.017*\"stori\" + 0.017*\"histori\" + 0.016*\"bestsel\"\n",
      "Topic: 6 \n",
      "Words: 0.058*\"american\" + 0.039*\"book\" + 0.033*\"america\" + 0.030*\"world\" + 0.026*\"self\" + 0.025*\"high\" + 0.024*\"true\" + 0.022*\"popular\" + 0.019*\"cultur\" + 0.017*\"centuri\"\n",
      "Topic: 7 \n",
      "Words: 0.065*\"world\" + 0.063*\"book\" + 0.021*\"year\" + 0.020*\"stori\" + 0.020*\"best\" + 0.018*\"word\" + 0.018*\"know\" + 0.017*\"time\" + 0.016*\"understand\" + 0.016*\"read\"\n",
      "Topic: 8 \n",
      "Words: 0.033*\"world\" + 0.031*\"time\" + 0.029*\"bestsel\" + 0.026*\"year\" + 0.025*\"book\" + 0.021*\"york\" + 0.021*\"author\" + 0.020*\"know\" + 0.017*\"like\" + 0.016*\"countri\"\n",
      "Topic: 9 \n",
      "Words: 0.032*\"book\" + 0.029*\"famili\" + 0.027*\"know\" + 0.024*\"help\" + 0.023*\"live\" + 0.019*\"break\" + 0.018*\"come\" + 0.017*\"discov\" + 0.016*\"learn\" + 0.016*\"find\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.023*\"busi\" + 0.021*\"plan\" + 0.019*\"build\" + 0.016*\"guid\" + 0.016*\"live\" + 0.014*\"famili\" + 0.013*\"want\" + 0.013*\"help\" + 0.013*\"start\" + 0.013*\"york\"\n",
      "Topic: 1 Word: 0.038*\"citi\" + 0.022*\"word\" + 0.019*\"grow\" + 0.019*\"murder\" + 0.018*\"figur\" + 0.016*\"seri\" + 0.016*\"illustr\" + 0.015*\"york\" + 0.014*\"year\" + 0.013*\"mysteri\"\n",
      "Topic: 2 Word: 0.022*\"beauti\" + 0.018*\"home\" + 0.017*\"like\" + 0.017*\"busi\" + 0.016*\"popular\" + 0.015*\"chang\" + 0.015*\"adventur\" + 0.015*\"discov\" + 0.014*\"hand\" + 0.014*\"grow\"\n",
      "Topic: 3 Word: 0.017*\"town\" + 0.016*\"world\" + 0.016*\"famili\" + 0.016*\"life\" + 0.014*\"kind\" + 0.014*\"countri\" + 0.013*\"mysteri\" + 0.013*\"live\" + 0.012*\"year\" + 0.012*\"past\"\n",
      "Topic: 4 Word: 0.019*\"life\" + 0.019*\"explor\" + 0.017*\"young\" + 0.017*\"scienc\" + 0.016*\"book\" + 0.016*\"best\" + 0.015*\"love\" + 0.014*\"novel\" + 0.014*\"experi\" + 0.013*\"world\"\n",
      "Topic: 5 Word: 0.042*\"book\" + 0.037*\"classic\" + 0.021*\"perfect\" + 0.019*\"hous\" + 0.018*\"self\" + 0.017*\"friend\" + 0.016*\"come\" + 0.015*\"human\" + 0.014*\"break\" + 0.014*\"read\"\n",
      "Topic: 6 Word: 0.021*\"stori\" + 0.014*\"histori\" + 0.014*\"power\" + 0.013*\"book\" + 0.012*\"import\" + 0.012*\"begin\" + 0.012*\"famili\" + 0.011*\"open\" + 0.011*\"read\" + 0.011*\"true\"\n",
      "Topic: 7 Word: 0.032*\"american\" + 0.022*\"reader\" + 0.018*\"stori\" + 0.017*\"includ\" + 0.016*\"tradit\" + 0.015*\"like\" + 0.015*\"world\" + 0.014*\"america\" + 0.013*\"book\" + 0.013*\"lead\"\n",
      "Topic: 8 Word: 0.033*\"page\" + 0.024*\"give\" + 0.022*\"life\" + 0.021*\"novel\" + 0.021*\"american\" + 0.018*\"experi\" + 0.017*\"person\" + 0.017*\"america\" + 0.017*\"take\" + 0.016*\"book\"\n",
      "Topic: 9 Word: 0.027*\"murder\" + 0.020*\"learn\" + 0.019*\"polit\" + 0.019*\"seri\" + 0.017*\"know\" + 0.015*\"star\" + 0.014*\"struggl\" + 0.014*\"origin\" + 0.013*\"detail\" + 0.013*\"human\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['road',\n",
       " 'trip',\n",
       " 'tale',\n",
       " 'travelogu',\n",
       " 'lose',\n",
       " 'landscap',\n",
       " 'good',\n",
       " 'natur',\n",
       " 'natur',\n",
       " 'histori',\n",
       " 'mariposa',\n",
       " 'road',\n",
       " 'track',\n",
       " 'pyle',\n",
       " 'journey',\n",
       " 'unit',\n",
       " 'state',\n",
       " 'race',\n",
       " 'calendarin',\n",
       " 'search',\n",
       " 'american',\n",
       " 'butterfli',\n",
       " 'like',\n",
       " 'pyle',\n",
       " 'classic',\n",
       " 'chase',\n",
       " 'monarch',\n",
       " 'mariposa',\n",
       " 'road',\n",
       " 'recount',\n",
       " 'adventur',\n",
       " 'high',\n",
       " 'track',\n",
       " 'butterfli',\n",
       " 'tech',\n",
       " 'individu',\n",
       " 'accompani',\n",
       " 'marsha',\n",
       " 'cottonwood',\n",
       " 'limb',\n",
       " 'butterfli',\n",
       " 'powdermilk',\n",
       " 'honda',\n",
       " 'civic',\n",
       " 'mile',\n",
       " 'odomet',\n",
       " 'small',\n",
       " 'leitz',\n",
       " 'binocular',\n",
       " 'carri',\n",
       " 'thirti',\n",
       " 'year',\n",
       " 'ventur',\n",
       " 'seri',\n",
       " 'remark',\n",
       " 'trip',\n",
       " 'northwest',\n",
       " 'home',\n",
       " 'california',\n",
       " 'coastlin',\n",
       " 'compani',\n",
       " 'overwint',\n",
       " 'monarch',\n",
       " 'northern',\n",
       " 'tundra',\n",
       " 'pursuit',\n",
       " 'mysteri',\n",
       " 'sulphur',\n",
       " 'arctic',\n",
       " 'zebra',\n",
       " 'daggerw',\n",
       " 'everglad',\n",
       " 'leafw',\n",
       " 'bluew',\n",
       " 'border',\n",
       " 'rariti',\n",
       " 'lower',\n",
       " 'grand',\n",
       " 'graceland',\n",
       " 'ranchland',\n",
       " 'kauai',\n",
       " 'west',\n",
       " 'intim',\n",
       " 'encount',\n",
       " 'land',\n",
       " 'peopl',\n",
       " 'fade',\n",
       " 'fauna',\n",
       " 'wholli',\n",
       " 'origin',\n",
       " 'turn',\n",
       " 'whimsic',\n",
       " 'witti',\n",
       " 'inform',\n",
       " 'inspir',\n",
       " 'mariposa',\n",
       " 'road',\n",
       " 'extraordinari',\n",
       " 'journey',\n",
       " 'discoveri',\n",
       " 'lead',\n",
       " 'reader',\n",
       " 'farther',\n",
       " 'butterfli',\n",
       " 'countri',\n",
       " 'deeper',\n",
       " 'heart',\n",
       " 'naturalist']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.5001440644264221\t \n",
      "Topic: 0.053*\"busi\" + 0.036*\"book\" + 0.031*\"chang\" + 0.023*\"help\" + 0.023*\"start\" + 0.021*\"learn\" + 0.020*\"creat\" + 0.019*\"plan\" + 0.019*\"know\" + 0.019*\"histori\"\n",
      "\n",
      "Score: 0.4527895450592041\t \n",
      "Topic: 0.032*\"book\" + 0.029*\"famili\" + 0.027*\"know\" + 0.024*\"help\" + 0.023*\"live\" + 0.019*\"break\" + 0.018*\"come\" + 0.017*\"discov\" + 0.016*\"learn\" + 0.016*\"find\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[1]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.5549411773681641\t \n",
      "Topic: 0.027*\"murder\" + 0.020*\"learn\" + 0.019*\"polit\" + 0.019*\"seri\" + 0.017*\"know\" + 0.015*\"star\" + 0.014*\"struggl\" + 0.014*\"origin\" + 0.013*\"detail\" + 0.013*\"human\"\n",
      "\n",
      "Score: 0.2296331375837326\t \n",
      "Topic: 0.019*\"life\" + 0.019*\"explor\" + 0.017*\"young\" + 0.017*\"scienc\" + 0.016*\"book\" + 0.016*\"best\" + 0.015*\"love\" + 0.014*\"novel\" + 0.014*\"experi\" + 0.013*\"world\"\n",
      "\n",
      "Score: 0.17424091696739197\t \n",
      "Topic: 0.032*\"american\" + 0.022*\"reader\" + 0.018*\"stori\" + 0.017*\"includ\" + 0.016*\"tradit\" + 0.015*\"like\" + 0.015*\"world\" + 0.014*\"america\" + 0.013*\"book\" + 0.013*\"lead\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[1]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
