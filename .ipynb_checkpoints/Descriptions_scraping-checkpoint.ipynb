{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Amazon Dataset Processing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Function to return: Author, ISBN-10, ISBN-13, platform, price, category1, category2, description</h3>\n",
    "\n",
    "Update From <b>Akshay, Zhuo</b> - \n",
    "<font color='red'>Information available from Kaggle:</font>\n",
    "\n",
    "<li>ISBN 10</li>\n",
    "<li>Author</li>\n",
    "<li>Platform</li>\n",
    "\n",
    "<b>Information Being scraped:</b>\n",
    "\n",
    "<li>Description</li>\n",
    "<li>Price</li>\n",
    "\n",
    "Categories aren't available for all books. We might have to skip this for the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Read data from amazon_com_extras. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## import pandas as pd\n",
    "import random \n",
    "import json\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "\n",
    "my_csvfile='./file2_lily2.csv' #please modify filename to your own need\n",
    "start_entry=2001\n",
    "end_entry=3000 #akshay already did 1~1000 entry, edit yours accordingly \n",
    "\n",
    "path_kaggle = './amazon_com_extras.csv' #download from https://www.kaggle.com/ucffool/amazon-sales-rank-data-for-print-and-kindle-books/version/3\n",
    "\n",
    "with open(path_kaggle):\n",
    "    #Added fields since line 808 in csv has more than 6 cols and needs to be told to ignore extra data.\n",
    "    \n",
    "    fields=['ASIN','GROUP','FORMAT','TITLE','AUTHOR','PUBLISHER']\n",
    "    df_kaggle = pd.read_csv(path_kaggle, encoding='latin1', dtype=str,usecols=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(df_kaggle))\n",
    "Df_read = df_kaggle.iloc[start_entry:end_entry+1]\n",
    "\n",
    "Df_read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Note: Amazon will identify and block you as a bot, please exercise caution while pulling data. Use user agents and throttling to prevent sending multilpe requests</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Agent Code - Refer https://www.scrapehero.com/how-to-fake-and-rotate-user-agents-using-python-3/\n",
    "\n",
    "Updated the following :\n",
    "\n",
    "<li>Throttling</li>\n",
    "<li>Saving data to a single dataframe</li>\n",
    "\n",
    "<h3> 1. Pull data from the Kaggle Dataset. We'll be using ISBN 10 to scrape book descriptions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "def amazon_description(book_metadata):\n",
    "    \n",
    "    import random\n",
    "    import time\n",
    "    \n",
    "    #New columns that will be added to book_metadata\n",
    "    book_descriptions=list()\n",
    "    book_price=list()\n",
    "    book_rating=list()\n",
    "    \n",
    "    user_agent_list = [\n",
    "           #Chrome\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 5.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "            #Firefox\n",
    "            'Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1)',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (Windows NT 6.2; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0; Trident/5.0)',\n",
    "            'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Win64; x64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)',\n",
    "            'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)',\n",
    "            'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729)'\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    book_metadata['Description']=''\n",
    "    book_metadata['Price']=''\n",
    "    book_metadata['Rating']=''\n",
    "    for i in range(len(book_metadata)):\n",
    "        \n",
    "        #User Agents to prevent bot detection\n",
    "        user_agent=random.choice(user_agent_list)\n",
    "        book_isbn=book_metadata['ASIN'].iloc[i]\n",
    "        \n",
    "        print(book_isbn)\n",
    "        base_url = \"https://www.amazon.com/s/ref=nb_sb_noss?url=search-alias%3Dstripbooks-intl-ship&field-keywords=\"\n",
    "        url=base_url+book_isbn\n",
    "        print(url)\n",
    "        headers={'User-Agent':user_agent}\n",
    "        book_response=requests.get(url,headers=headers)\n",
    "        if book_response.status_code != 200:\n",
    "            print(\"Getting Book Details Failed\")\n",
    "            return None\n",
    "        else:\n",
    "            result_page=bs(book_response.content,'lxml')\n",
    "            all_book_a_tags=result_page.find(\"a\",class_=\"a-link-normal s-access-detail-page s-color-twister-title-link a-text-normal\")\n",
    "            try:\n",
    "                book_url=all_book_a_tags.get(\"href\")\n",
    "                description,price,rating=get_book_description(book_url,user_agent_list)\n",
    "            except: \n",
    "                continue\n",
    "            print(description,price,rating)\n",
    "\n",
    "        book_metadata['Description'].iloc[i]=description\n",
    "        book_metadata['Price'].iloc[i]=price\n",
    "        book_metadata['Rating'].iloc[i]=rating\n",
    "        book_metadata.to_csv(my_csvfile,encoding='utf-8') #save data after each query\n",
    "\n",
    "    \n",
    "    return book_metadata\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Write code to pull the following - </h3>\n",
    " \n",
    "<h4> \n",
    "<li> Description </li>\n",
    "<li> Rating </li>\n",
    "<li> Price </li>\n",
    "\n",
    "    \n",
    "</h4>    \n",
    "\n",
    "<h3> Ans save data at the same time to the local file  </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_book_description(url,user_agent_list):\n",
    "    book_description=''\n",
    "    book_rating=''\n",
    "    book_price=''\n",
    "    print(url)\n",
    "    #User Agents to prevent bot detection\n",
    "    user_agent = random.choice(user_agent_list)\n",
    "    headers = {'User-Agent': user_agent}\n",
    "    \n",
    "    #Throttling to spoof the server into believe these are generated by users\n",
    "    time.sleep(7)\n",
    "    \n",
    "    book_description_response=requests.get(url,headers=headers)\n",
    "    if book_description_response.status_code!=200:\n",
    "        print(\"Error in scraping description\")\n",
    "        return None\n",
    "    else:\n",
    "        book_page=bs(book_description_response.content,\"lxml\")\n",
    "        a1=book_page.find('div',{'id':'a-page'})\n",
    "        a2=a1.find('div',class_='book en_US').find('div',class_='a-container').find('div',{'id':'centerCol'})\n",
    "        try:\n",
    "            book_description=a2.find('div',{'id':'bookDescription_feature_div'}).find('noscript').find('div').get_text()\n",
    "        except:\n",
    "            book_description=np.NAN\n",
    "        try:\n",
    "            book_rating=a2.find('div',{'id':'averageCustomerReviews_feature_div'}).find('span',class_='a-declarative').find('span',{'id':'acrPopover'}).find('span',class_='a-declarative').find('a').find('i').find('span').get_text().split()[0]    \n",
    "        except:\n",
    "            book_rating=np.NAN\n",
    "        try:\n",
    "            book_price=a2.find('div',{'id':'MediaMatrix'}).find('div').find('div',{'id':'tmmSwatches'}).find('ul').find('li',class_='swatchElement selected').find('span').find('span').find('span').find('span',class_='a-color-base').find('span').get_text().strip()\n",
    "        except:\n",
    "            book_price=np.NAN\n",
    "        return book_description,book_price,book_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=amazon_description(Df_read) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
