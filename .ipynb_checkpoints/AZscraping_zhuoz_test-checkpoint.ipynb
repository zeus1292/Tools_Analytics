{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Amazon Dataset Processing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Function to return: Author, ISBN-10, ISBN-13, platform, price, category1, category2, description</h3>\n",
    "\n",
    "Update From <b>Akshay</b> - \n",
    "<font color='red'>Information available from Kaggle:</font>\n",
    "\n",
    "<li>ISBN 10</li>\n",
    "<li>Author</li>\n",
    "<li>Platform</li>\n",
    "\n",
    "<b>Information Being scraped:</b>\n",
    "\n",
    "<li>Description</li>\n",
    "<li>Price</li>\n",
    "\n",
    "Categories aren't available for all books. We might have to skip this for the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Read data from amazon_com_extras. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#path_kaggle = r'C:\\Users\\endwy\\Documents\\Columbia MSBA\\Fall 2018\\E4501 - Tools for Analytics\\Project\\kaggle data\\amazon_com_extras.csv'\n",
    "path_kaggle = './amazon_com_extras.csv' #download from https://www.kaggle.com/ucffool/amazon-sales-rank-data-for-print-and-kindle-books/version/3\n",
    "\n",
    "with open(path_kaggle):\n",
    "    #Added fields since line 808 in csv has more than 6 cols and needs to be told to ignore extra data.\n",
    "    \n",
    "    fields=['ASIN','GROUP','FORMAT','TITLE','AUTHOR','PUBLISHER']\n",
    "    df_kaggle = pd.read_csv(path_kaggle, encoding='latin1', dtype=str,usecols=fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Note: Amazon will identify and block you as a bot, please exercise caution while pulling data. Use user agents and throttling to prevent sending multilpe requests</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Agent Code - Refer https://www.scrapehero.com/how-to-fake-and-rotate-user-agents-using-python-3/\n",
    "\n",
    "Updated the following :\n",
    "\n",
    "<li>Throttling</li>\n",
    "<li>Saving data to a single dataframe</li>\n",
    "\n",
    "<h3> 1. Pull data from the Kaggle Dataset. We'll be using ISBN 10 to scrape book descriptions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "def amazon_description(book_metadata):\n",
    "    \n",
    "    import random\n",
    "    import time\n",
    "    \n",
    "    #New columns that will be added to book_metadata\n",
    "    book_descriptions=list()\n",
    "    book_price=list()\n",
    "    book_rating=list()\n",
    "    \n",
    "    user_agent_list = [\n",
    "           #Chrome\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 5.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "            #Firefox\n",
    "            'Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1)',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (Windows NT 6.2; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0; Trident/5.0)',\n",
    "            'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)',\n",
    "            'Mozilla/5.0 (Windows NT 6.1; Win64; x64; Trident/7.0; rv:11.0) like Gecko',\n",
    "            'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)',\n",
    "            'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)',\n",
    "            'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729)'\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(book_metadata)):\n",
    "        \n",
    "        #User Agents to prevent bot detection\n",
    "        user_agent=random.choice(user_agent_list)\n",
    "        book_isbn=book_metadata['ASIN'].iloc[i]\n",
    "        print(book_isbn)\n",
    "        base_url = \"https://www.amazon.com/s/ref=nb_sb_noss?url=search-alias%3Dstripbooks-intl-ship&field-keywords=\"\n",
    "        url=base_url+book_isbn\n",
    "        print(url)\n",
    "        headers={'User-Agent':user_agent}\n",
    "        book_response=requests.get(url,headers=headers)\n",
    "        if book_response.status_code != 200:\n",
    "            print(\"Getting Book Details Failed\")\n",
    "            return None\n",
    "        else:\n",
    "            result_page=bs(book_response.content,'lxml')\n",
    "            all_book_a_tags=result_page.find(\"a\",class_=\"a-link-normal s-access-detail-page s-color-twister-title-link a-text-normal\")\n",
    "            book_url=all_book_a_tags.get(\"href\")\n",
    "            description,price,rating=get_book_description(book_url,user_agent_list)\n",
    "            print(description,price,rating)\n",
    "            book_descriptions.append(description)\n",
    "            book_price.append(price)\n",
    "            book_rating.append(rating)\n",
    "    \n",
    "    book_metadata['Description']=book_descriptions\n",
    "    book_metadata['Price']=book_price\n",
    "    book_metadata['Rating']=book_rating\n",
    "    \n",
    "    return book_metadata\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Write code to pull the following - </h3>\n",
    " \n",
    "<h4> \n",
    "<li> Description </li>\n",
    "<li> Rating </li>\n",
    "<li> Price </li>\n",
    "    \n",
    "</h4>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_description(url,user_agent_list):\n",
    "    book_description=''\n",
    "    book_rating=''\n",
    "    book_price=''\n",
    "    print(url)\n",
    "    #User Agents to prevent bot detection\n",
    "    user_agent = random.choice(user_agent_list)\n",
    "    headers = {'User-Agent': user_agent}\n",
    "    \n",
    "    #Throttling to spoof the server into believe these are generated by users\n",
    "    time.sleep(7)\n",
    "    \n",
    "    book_description_response=requests.get(url,headers=headers)\n",
    "    if book_description_response.status_code!=200:\n",
    "        print(\"Error in scraping description\")\n",
    "        return None\n",
    "    else:\n",
    "        book_page=bs(book_description_response.content,\"lxml\")\n",
    "        a1=book_page.find('div',{'id':'a-page'})\n",
    "        a2=a1.find('div',class_='book en_US').find('div',class_='a-container').find('div',{'id':'centerCol'})\n",
    "        try:\n",
    "            book_description=a2.find('div',{'id':'bookDescription_feature_div'}).find('noscript').find('div').get_text()\n",
    "        except:\n",
    "            book_description=np.NAN\n",
    "        try:\n",
    "            book_rating=a2.find('div',{'id':'averageCustomerReviews_feature_div'}).find('span',class_='a-declarative').find('span',{'id':'acrPopover'}).find('span',class_='a-declarative').find('a').find('i').find('span').get_text().split()[0]    \n",
    "        except:\n",
    "            book_rating=np.NAN\n",
    "        try:\n",
    "            book_price=a2.find('div',{'id':'MediaMatrix'}).find('div').find('div',{'id':'tmmSwatches'}).find('ul').find('li',class_='swatchElement selected').find('span').find('span').find('span').find('span',class_='a-color-base').find('span').get_text().strip()\n",
    "        except:\n",
    "            book_price=np.NAN\n",
    "        return book_description,book_price,book_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> You might need to batch the kaggle dataset into sets of 1000 rows. Takes a few hours to run</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-af8f2137e4cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamazon_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#Be very careful when running the function\n",
    "df_final=amazon_description(df_kaggle) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Save the file. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('file1.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Rename ISBN-13 to ASIN for future merge</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIN</th>\n",
       "      <th>ISBN-10</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>link</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ASIN, ISBN-10, title, author, rating, price, category1, category2, num_reviews, link, description]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_az.rename(columns={'ISBN-13':'ASIN'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Kaggle Dataset Processing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><font color='red'>Note:</font color='red'> you will need to change the path to your directory when you want to run/edit</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. File import</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#path_kaggle = r'C:\\Users\\endwy\\Documents\\Columbia MSBA\\Fall 2018\\E4501 - Tools for Analytics\\Project\\kaggle data\\amazon_com_extras.csv'\n",
    "path_kaggle = './amazon_com_extras.csv' #download from https://www.kaggle.com/ucffool/amazon-sales-rank-data-for-print-and-kindle-books/version/3\n",
    "\n",
    "with open(path_kaggle):\n",
    "    #Added fields since line 808 in csv has more than 6 cols and needs to be told to ignore extra data.\n",
    "    \n",
    "    fields=['ASIN','GROUP','FORMAT','TITLE','AUTHOR','PUBLISHER']\n",
    "    df_kaggle = pd.read_csv(path_kaggle, encoding='latin1', dtype=str,usecols=fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Merge Amazon scrape andKkaggle dfs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ASIN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4114ccfc9566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_az\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_kaggle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ASIN'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/LovelyCheuk/anaconda/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     59\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LovelyCheuk/anaconda/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    549\u001b[0m         (self.left_join_keys,\n\u001b[1;32m    550\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LovelyCheuk/anaconda/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    869\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m                         left_keys.append(left._get_label_or_level_values(\n\u001b[0;32m--> 871\u001b[0;31m                             lk, stacklevel=stacklevel))\n\u001b[0m\u001b[1;32m    872\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LovelyCheuk/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis, stacklevel)\u001b[0m\n\u001b[1;32m   1380\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ASIN'"
     ]
    }
   ],
   "source": [
    "# merge = pd.merge(df_az,df_kaggle, on='ASIN',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Save out</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge.to_csv('C:\\Users\\endwy\\Documents\\Columbia MSBA\\Fall 2018\\E4501 - Tools for Analytics\\Project\\kaggle data\\processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color='red'>Note: </font color='red'></h1><h2>Running the following will convert .ipynb to .py </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script AZscraping.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
