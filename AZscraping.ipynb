{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Amazon Dataset Processing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Function to return: Author, ISBN-10, ISBN-13, platform, price, category1, category2, description</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aiipp(link):\n",
    "    \"\"\"Returns lists of Author, ISBN-10, ISBN-13, platform, price, category1, category2, description for book\"\"\"\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    page = requests.get(link)\n",
    "    results_page = BeautifulSoup(page.content,'lxml')\n",
    "    \n",
    "    m = results_page.find('a', class_='a-link-normal contributorNameID').get_text()\n",
    "    book_authors.append(m)\n",
    "    n = results_page.find('div', class_='content').find_all('li')[5].get_text().replace('ISBN-10:','').strip()\n",
    "    book_isbn10.append(n)\n",
    "    p = results_page.find('div', class_='content').find_all('li')[6].get_text().replace('ISBN-13:','').strip()\n",
    "    book_isbn13.append(p)\n",
    "    q = int(results_page.find_all('span',class_='a-size-base')[1].get_text().replace('customer reviews','').strip())\n",
    "    book_num_customer_reviews.append(q)\n",
    "    s = float(results_page.find_all('span',class_='p13n-sc-price')[1].get_text()[1:])\n",
    "    book_prices.append(s)\n",
    "    t = results_page.find('div',class_='a-subheader a-breadcrumb feature').find_all('li')[2].find('a',class_='a-link-normal a-color-tertiary').get_text().replace('\\n','').strip()\n",
    "    book_category1.append(t)\n",
    "    u = results_page.find('div',class_='a-subheader a-breadcrumb feature').find_all('li')[4].find('a',class_='a-link-normal a-color-tertiary').get_text().replace('\\n','').strip()\n",
    "    book_category2.append(u)\n",
    "    \n",
    "    #v = @Akshay to insert description code\n",
    "    #book_description.append(v)\n",
    "    \n",
    "    from time import sleep\n",
    "    sleep(15)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Titles, links, ratings</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "\n",
    "link_home = 'https://www.amazon.com/best-sellers-books-Amazon/zgbs/books'\n",
    "page = requests.get(link_home)\n",
    "results_page = BeautifulSoup(page.content,'lxml')\n",
    "all_links = results_page.find_all('li',class_='zg-item-immersion')\n",
    "\n",
    "book_links = list()\n",
    "book_titles = list()\n",
    "book_ratings = list()\n",
    "book_authors = list()\n",
    "book_isbn10 = list()\n",
    "book_isbn13 = list()\n",
    "book_num_customer_reviews = list()\n",
    "book_prices = list()\n",
    "book_category1 = list()\n",
    "book_category2 = list()\n",
    "book_description = list()\n",
    "\n",
    "for i in all_links:\n",
    "    m = 'https://www.amazon.com%s' %(i.find('a', class_='a-link-normal').get('href'))\n",
    "    book_links.append(m)\n",
    "    \n",
    "for i in all_links:\n",
    "    m = i.find('div',class_='p13n-sc-truncate p13n-sc-line-clamp-1').get_text()\n",
    "    m = m.replace('\\n','')\n",
    "    m = m.strip()\n",
    "    book_titles.append(m)\n",
    "\n",
    "for i in all_links:\n",
    "    m = i.find_all('a',class_='a-link-normal')[1].get_text()\n",
    "    if '$' in m:\n",
    "        book_ratings.append('No Rating')\n",
    "    else:\n",
    "        m = m.replace('\\n','')\n",
    "        m = m.strip()\n",
    "        m = m[:3]\n",
    "        book_ratings.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in book_links:\n",
    "    get_aiipp(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Zip all elements together & create pd.df</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_az = list(zip(book_isbn13,book_isbn10,book_titles,book_authors,book_ratings,book_prices,book_category1,\n",
    "         book_category2,book_num_customer_reviews,book_links,book_description))\n",
    "labels = ['ISBN-13','ISBN-10','title','author','rating','price','category1','category2','num_reviews','link','description']\n",
    "df_az = pd.DataFrame.from_records(zip_az,columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Rename ISBN-13 to ASIN for future merge</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_az.rename(columns={'ISBN-13':'ASIN'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Kaggle Dataset Processing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><font color='red'>Note:</font color='red'> you will need to change the path to your directory when you want to run/edit</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. File import</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path_kaggle = r'C:\\Users\\endwy\\Documents\\Columbia MSBA\\Fall 2018\\E4501 - Tools for Analytics\\Project\\kaggle data\\amazon_com_extras.csv'\n",
    "\n",
    "with open(path_kaggle):\n",
    "    df_kaggle = pd.read_csv(path_kaggle, encoding='latin1', dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Remove \"spill over\" unnamed rows from df</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols_unnamed = ['Unnamed: 6','Unnamed: 7','Unnamed: 8','Unnamed: 9',\n",
    "                'Unnamed: 10','Unnamed: 11','Unnamed: 12','Unnamed: 13','Unnamed: 14']\n",
    "for i in cols_unnamed:\n",
    "    for index, row in df_kaggle.iterrows():\n",
    "        if df_kaggle.loc[index,[str(i)]].isnull().any()==False:\n",
    "                df_kaggle.drop([index],inplace=True)\n",
    "df_kaggle.drop(['Unnamed: 6','Unnamed: 7','Unnamed: 8','Unnamed: 9',\n",
    "                'Unnamed: 10','Unnamed: 11','Unnamed: 12','Unnamed: 13','Unnamed: 14'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Merge Amazon scrape andKkaggle dfs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.merge(df_az,df_kaggle, on='ASIN',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Save out</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.to_csv('C:\\Users\\endwy\\Documents\\Columbia MSBA\\Fall 2018\\E4501 - Tools for Analytics\\Project\\kaggle data\\processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color='red'>Note: </font color='red'></h1><h2>Running the following will convert .ipynb to .py </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script AZscraping.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
